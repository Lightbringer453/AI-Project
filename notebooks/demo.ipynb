{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multi-Purpose Image Detection and Analysis System\n",
        "\n",
        "This notebook demonstrates the usage of the image detection and analysis pipeline.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add parent directory to path\n",
        "sys.path.insert(0, str(Path().resolve().parent))\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "from app.main import ImageAnalysisPipeline\n",
        "from utils.image_loader import load_image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Initialize Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the pipeline with YOLOv8 detector\n",
        "pipeline = ImageAnalysisPipeline(detector_type=\"yolo\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load and Process Image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load image (replace with your image path)\n",
        "image_path = \"../test_image.jpg\"  # Update this path\n",
        "\n",
        "# Or use a sample image URL\n",
        "# import urllib.request\n",
        "# urllib.request.urlretrieve(\"https://example.com/image.jpg\", \"sample.jpg\")\n",
        "# image_path = \"sample.jpg\"\n",
        "\n",
        "try:\n",
        "    image = load_image(image_path)\n",
        "    print(f\"Image loaded: {image.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Image not found at {image_path}\")\n",
        "    print(\"Please update the image_path variable with a valid image path\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Run Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process the image\n",
        "result = pipeline.process_image(image_path, save_output=True)\n",
        "\n",
        "# Print summary\n",
        "print(\"=\" * 50)\n",
        "print(\"ANALYSIS SUMMARY\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Total detections: {result['summary']['total_detections']}\")\n",
        "print(f\"Humans: {result['summary']['humans']}\")\n",
        "print(f\"Animals: {result['summary']['animals']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Display Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display original and annotated images\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
        "\n",
        "# Original image\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "axes[0].imshow(image_rgb)\n",
        "axes[0].set_title(\"Original Image\")\n",
        "axes[0].axis(\"off\")\n",
        "\n",
        "# Annotated image\n",
        "if result['annotated_image'] is not None:\n",
        "    annotated_rgb = cv2.cvtColor(result['annotated_image'], cv2.COLOR_BGR2RGB)\n",
        "    axes[1].imshow(annotated_rgb)\n",
        "    axes[1].set_title(\"Annotated Image\")\n",
        "    axes[1].axis(\"off\")\n",
        "else:\n",
        "    axes[1].text(0.5, 0.5, \"No detections found\", ha=\"center\", va=\"center\")\n",
        "    axes[1].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Detailed Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print detailed results for each detection\n",
        "for i, detection in enumerate(result['detections'], 1):\n",
        "    print(f\"\\n{'=' * 50}\")\n",
        "    print(f\"Detection {i}\")\n",
        "    print(f\"{'=' * 50}\")\n",
        "    print(f\"Type: {detection['class_type']}\")\n",
        "    print(f\"Class: {detection.get('class_name', 'N/A')}\")\n",
        "    print(f\"Confidence: {detection.get('confidence', 0.0):.2%}\")\n",
        "    print(f\"BBox: {detection['bbox']}\")\n",
        "    \n",
        "    attributes = detection.get('attributes', {})\n",
        "    if detection['class_type'] == 'human':\n",
        "        print(f\"Age: {attributes.get('age', 'N/A')}\")\n",
        "        print(f\"Gender: {attributes.get('gender', 'N/A')}\")\n",
        "        print(f\"Emotion: {attributes.get('emotion', 'N/A')}\")\n",
        "    elif detection['class_type'] == 'animal':\n",
        "        print(f\"Species: {attributes.get('species', 'N/A')}\")\n",
        "        print(f\"Breed: {attributes.get('breed', 'N/A')}\")\n",
        "        print(f\"Maturity: {attributes.get('maturity', 'N/A')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. JSON Output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get JSON output\n",
        "import json\n",
        "\n",
        "json_output = pipeline.process_image_to_json(image_path)\n",
        "print(json_output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Individual Component Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test individual components\n",
        "from models.yolo_detector import YOLODetector\n",
        "from models.human_analysis import HumanAnalyzer\n",
        "from models.animal_analysis import AnimalAnalyzer\n",
        "\n",
        "# Test detector only\n",
        "detector = YOLODetector()\n",
        "detections = detector.detect(image)\n",
        "print(f\"Detected {len(detections)} objects\")\n",
        "\n",
        "# Test human analyzer (if human detected)\n",
        "human_detections = [d for d in detections if d['class_type'] == 'human']\n",
        "if human_detections:\n",
        "    from utils.image_loader import crop_image\n",
        "    human_analyzer = HumanAnalyzer()\n",
        "    crop = crop_image(image, human_detections[0]['bbox'])\n",
        "    human_attrs = human_analyzer.analyze_human(crop)\n",
        "    print(f\"Human attributes: {human_attrs}\")\n",
        "\n",
        "# Test animal analyzer (if animal detected)\n",
        "animal_detections = [d for d in detections if d['class_type'] == 'animal']\n",
        "if animal_detections:\n",
        "    animal_analyzer = AnimalAnalyzer()\n",
        "    crop = crop_image(image, animal_detections[0]['bbox'])\n",
        "    species = animal_detections[0].get('class_name', 'unknown')\n",
        "    animal_attrs = animal_analyzer.analyze_animal(crop, species)\n",
        "    print(f\"Animal attributes: {animal_attrs}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
