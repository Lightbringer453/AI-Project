"""
Dataset'i Hugging Face'ten indirip organize eden script.

Dataset: animals-10 (26k+ fotoÄŸraf)
Kaynak: https://huggingface.co/datasets/dgrnd4/animals-10

KullanÄ±m:
    python download_animals_dataset.py
"""

from datasets import load_dataset
from pathlib import Path
from PIL import Image
import os
from tqdm import tqdm


def download_and_organize_dataset(output_dir="animal_dataset", max_images_per_class=500):
    """
    Animals-10 dataset'ini indir ve organize et.
    
    Args:
        output_dir: Ã‡Ä±ktÄ± klasÃ¶rÃ¼
        max_images_per_class: Her sÄ±nÄ±f iÃ§in maksimum gÃ¶rsel sayÄ±sÄ± (RAM tasarrufu iÃ§in)
    """
    print("=" * 70)
    print("ANIMALS-10 DATASET Ä°NDÄ°RME VE ORGANÄ°ZASYON")
    print("=" * 70)
    
    # Dataset'i yÃ¼kle
    print("\n1. Dataset yÃ¼kleniyor (bu biraz zaman alabilir)...")
    try:
        # Train split'i yÃ¼kle (daha fazla veri iÃ§in)
        dataset = load_dataset("dgrnd4/animals-10", split="train")
        print(f"   âœ“ Dataset yÃ¼klendi: {len(dataset)} gÃ¶rsel")
    except Exception as e:
        print(f"   âœ— Hata: {e}")
        print("\n   Alternatif yÃ¶ntem deneniyor...")
        try:
            dataset = load_dataset("dgrnd4/animals-10")
            dataset = dataset["train"]
            print(f"   âœ“ Dataset yÃ¼klendi: {len(dataset)} gÃ¶rsel")
        except Exception as e2:
            print(f"   âœ— Hata: {e2}")
            return False
    
    # Output klasÃ¶rÃ¼nÃ¼ oluÅŸtur
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True, parents=True)
    
    print(f"\n2. GÃ¶rseller '{output_dir}' klasÃ¶rÃ¼ne kaydediliyor...")
    
    # SÄ±nÄ±f isimlerini al
    if hasattr(dataset.features["label"], "names"):
        class_names = dataset.features["label"].names
    else:
        # Manuel olarak sÄ±nÄ±f isimlerini belirle (animals-10 iÃ§in)
        class_names = [
            "dog", "cat", "horse", "spider", "butterfly",
            "chicken", "sheep", "cow", "squirrel", "elephant"
        ]
    
    print(f"   SÄ±nÄ±flar: {', '.join(class_names)}")
    
    # Her sÄ±nÄ±f iÃ§in klasÃ¶r oluÅŸtur
    for class_name in class_names:
        class_path = output_path / class_name
        class_path.mkdir(exist_ok=True)
    
    # GÃ¶rselleri organize et
    class_counts = {name: 0 for name in class_names}
    
    print("\n3. GÃ¶rseller iÅŸleniyor...")
    for idx, item in enumerate(tqdm(dataset, desc="   Progress")):
        # Label'Ä± al
        label = item["label"]
        class_name = class_names[label]
        
        # Maksimum sayÄ±ya ulaÅŸÄ±ldÄ±ysa atla
        if class_counts[class_name] >= max_images_per_class:
            continue
        
        # GÃ¶rseli al
        image = item["image"]
        
        # GÃ¶rseli kaydet
        image_filename = f"{class_name}_{class_counts[class_name]:04d}.jpg"
        image_path = output_path / class_name / image_filename
        
        try:
            # RGB'ye Ã§evir (eÄŸer grayscale ise)
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # Kaydet
            image.save(image_path, 'JPEG', quality=95)
            class_counts[class_name] += 1
        except Exception as e:
            print(f"\n   âš  GÃ¶rsel kaydedilemedi: {image_filename} - {e}")
            continue
    
    # SonuÃ§larÄ± gÃ¶ster
    print("\n" + "=" * 70)
    print("SONUÃ‡")
    print("=" * 70)
    print(f"\nâœ“ Dataset baÅŸarÄ±yla organize edildi!\n")
    print("SÄ±nÄ±f baÅŸÄ±na gÃ¶rsel sayÄ±sÄ±:")
    total = 0
    for class_name, count in sorted(class_counts.items()):
        print(f"   {class_name:12s}: {count:4d} gÃ¶rsel")
        total += count
    print(f"\n   {'TOPLAM':12s}: {total:4d} gÃ¶rsel")
    
    print(f"\nğŸ“ Dataset konumu: {output_path.absolute()}")
    
    return True


def prepare_for_training(dataset_dir="animal_dataset"):
    """
    Dataset'i eÄŸitim iÃ§in organize et (tÃ¼rlere gÃ¶re grupla).
    """
    dataset_path = Path(dataset_dir)
    
    # Evcil hayvanlar ve Ã§iftlik hayvanlarÄ± iÃ§in alt klasÃ¶rler oluÅŸtur
    categories = {
        "pets": ["dog", "cat"],
        "farm": ["horse", "sheep", "cow", "chicken"],
        "wild": ["elephant", "squirrel"],
        "others": ["spider", "butterfly"]
    }
    
    print("\n" + "=" * 70)
    print("EÄÄ°TÄ°M Ä°Ã‡Ä°N Ã–NERÄ°LER")
    print("=" * 70)
    
    print("\n1. KÃ¶pek Ä±rklarÄ± iÃ§in eÄŸitim:")
    print("   python train_breed_classifier.py \\")
    print(f"       --dataset_path \"{dataset_path / 'dog'}\" \\")
    print("       --species dog --samples_per_breed 50")
    
    print("\n2. Kedi Ä±rklarÄ± iÃ§in eÄŸitim:")
    print("   python train_breed_classifier.py \\")
    print(f"       --dataset_path \"{dataset_path / 'cat'}\" \\")
    print("       --species cat --samples_per_breed 50")
    
    print("\n3. DiÄŸer hayvanlar iÃ§in eÄŸitim:")
    print("   python train_breed_classifier.py \\")
    print(f"       --dataset_path \"{dataset_path / 'horse'}\" \\")
    print("       --species horse --samples_per_breed 30")
    
    print("\nâš  NOT: animals-10 dataset'i tÃ¼rler (species) iÃ§eriyor, Ä±rklar (breeds) deÄŸil.")
    print("   Daha iyi Ä±rk tespiti iÃ§in breed-specific dataset'ler bulman gerekebilir.")
    print("\n   Ã–rnek breed dataset'ler:")
    print("   - Stanford Dogs Dataset (120 kÃ¶pek Ä±rÄŸÄ±)")
    print("   - Oxford-IIIT Pet Dataset (37 kedi ve kÃ¶pek Ä±rÄŸÄ±)")
    

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Animals-10 dataset'ini indir ve organize et")
    parser.add_argument(
        "--output_dir",
        type=str,
        default="animal_dataset",
        help="Ã‡Ä±ktÄ± klasÃ¶rÃ¼ (varsayÄ±lan: animal_dataset)"
    )
    parser.add_argument(
        "--max_per_class",
        type=int,
        default=500,
        help="Her sÄ±nÄ±f iÃ§in maksimum gÃ¶rsel sayÄ±sÄ± (varsayÄ±lan: 500)"
    )
    
    args = parser.parse_args()
    
    print("\nğŸ¾ Animals-10 Dataset Ä°ndirme AracÄ±\n")
    
    # Dataset'i indir ve organize et
    success = download_and_organize_dataset(
        output_dir=args.output_dir,
        max_images_per_class=args.max_per_class
    )
    
    if success:
        # EÄŸitim Ã¶nerilerini gÃ¶ster
        prepare_for_training(args.output_dir)
        
        print("\n" + "=" * 70)
        print("BÄ°R SONRAKÄ° ADIM")
        print("=" * 70)
        print("\nâš  Ã–NEMLÄ°: Bu dataset TÃœRLER iÃ§eriyor, IRKLAR deÄŸil!")
        print("\nIrk tespiti iÃ§in iki seÃ§enek:")
        print("\n1. Bu dataset ile tÃ¼r tespitini geliÅŸtir:")
        print("   - Daha doÄŸru kÃ¶pek/kedi/at tespiti")
        print("   - Mevcut sistemini iyileÅŸtir")
        
        print("\n2. Breed-specific dataset bul:")
        print("   - Stanford Dogs: 120 kÃ¶pek Ä±rÄŸÄ±")
        print("   - Oxford Pets: 37 kedi/kÃ¶pek Ä±rÄŸÄ±")
        print("   - Kaggle'da birÃ§ok breed dataset var")
        
        print("\n" + "=" * 70)
    else:
        print("\nâœ— Dataset indirme baÅŸarÄ±sÄ±z oldu.")
        print("\nAlternatif: Manuel indirme")
        print("1. https://huggingface.co/datasets/dgrnd4/animals-10 adresini ziyaret et")
        print("2. Dataset'i manuel olarak indir")
        print("3. 'animal_dataset' klasÃ¶rÃ¼ne Ã§Ä±kart")
